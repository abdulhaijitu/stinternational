# ST International - Robots.txt
# Primary Domain: https://stinternationalbd.com

# Allow all crawlers on main domain
User-agent: Googlebot
Allow: /
Disallow: /admin
Disallow: /admin/*

User-agent: Bingbot
Allow: /
Disallow: /admin
Disallow: /admin/*

User-agent: Twitterbot
Allow: /

User-agent: facebookexternalhit
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: WhatsApp
Allow: /

User-agent: *
Allow: /
Disallow: /admin
Disallow: /admin/*
Disallow: /checkout
Disallow: /account
Disallow: /orders
Disallow: /cart
Disallow: /wishlist

# Primary Domain Sitemap
Sitemap: https://stinternationalbd.com/sitemap.xml

# Dynamic Sitemap (generated from database)
Sitemap: https://tmdktmnoeqezkbdaaayh.supabase.co/functions/v1/generate-sitemap

# Crawl-delay for polite crawling
Crawl-delay: 1

# Block preview/staging domains from indexing
# Note: Preview domains have noindex meta tags applied programmatically
